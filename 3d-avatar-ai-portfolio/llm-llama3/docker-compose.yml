version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    entrypoint: ["/usr/bin/bash", "/entrypoint.sh"]
    command: "ollama pull llama3.2"
    volumes:
      - ./prompt.txt:/app/prompt.txt
      - ./entrypoint.sh:/entrypoint.sh
    deploy:
      resources:
        limits:
          memory: 15G  # Ajusta esto según tus necesidades
        reservations:
          memory: 8G  # Este es el mínimo garantizado

  flask:
    build: ./flask-app
    ports:
      - "5000:5000"
    depends_on:
      - ollama
    environment:
      - OLLAMA_URL=http://ollama:11434/api/generate



# curl test command:

#curl -X POST http://localhost:11434/api/generate -H "Content-Type: application/json" -d "{\"model\": \"llama3.2\", \"prompt\":\"Qué proyectos has desarrollado en Java?\", \"stream\": false}"
#curl -X POST http://localhost:5000/ask -H "Content-Type: application/json" -d "{\"question\": \"¿Qué proyectos has desarrollado en Java?\"}"


